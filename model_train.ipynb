{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_test_split.pkl', 'rb') as f:\n",
    "    x_train, x_test, y_train, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),  ##Hidden Layer 1\n",
    "    Dense(32, activation='relu'),  ##Hidden Layer 2\n",
    "    Dense(1, activation='sigmoid')  ##Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                832       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "optimizser = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compiling the model\n",
    "\n",
    "model.compile(optimizer=optimizser, loss='binary_crossentropy', metrics=['accuracy', 'mse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above are the 2 ways to give values to a model.You can either pass it in the form of an array or you can directly initialize it to a variable and pass the vaariable as an argument to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the tensorboard\n",
    "\n",
    "log_dir = 'logs/fit/'+datetime.datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up earlystopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 0s 752us/step - loss: 0.1876 - accuracy: 0.9189 - mse: 0.0579 - mae: 0.1152 - val_loss: 0.7935 - val_accuracy: 0.8305 - val_mse: 0.1386 - val_mae: 0.2027\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 682us/step - loss: 0.1840 - accuracy: 0.9189 - mse: 0.0574 - mae: 0.1141 - val_loss: 0.7876 - val_accuracy: 0.8300 - val_mse: 0.1356 - val_mae: 0.1971\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.1870 - accuracy: 0.9210 - mse: 0.0577 - mae: 0.1152 - val_loss: 0.7833 - val_accuracy: 0.8320 - val_mse: 0.1375 - val_mae: 0.1965\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 671us/step - loss: 0.1822 - accuracy: 0.9225 - mse: 0.0558 - mae: 0.1112 - val_loss: 0.8435 - val_accuracy: 0.8300 - val_mse: 0.1400 - val_mae: 0.1938\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 716us/step - loss: 0.1846 - accuracy: 0.9210 - mse: 0.0571 - mae: 0.1139 - val_loss: 0.8097 - val_accuracy: 0.8335 - val_mse: 0.1367 - val_mae: 0.1924\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.1838 - accuracy: 0.9229 - mse: 0.0565 - mae: 0.1110 - val_loss: 0.8159 - val_accuracy: 0.8320 - val_mse: 0.1361 - val_mae: 0.1899\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.1880 - accuracy: 0.9166 - mse: 0.0589 - mae: 0.1161 - val_loss: 0.7692 - val_accuracy: 0.8295 - val_mse: 0.1364 - val_mae: 0.1911\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 735us/step - loss: 0.1876 - accuracy: 0.9210 - mse: 0.0580 - mae: 0.1156 - val_loss: 0.7981 - val_accuracy: 0.8325 - val_mse: 0.1387 - val_mae: 0.1980\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 678us/step - loss: 0.1886 - accuracy: 0.9168 - mse: 0.0586 - mae: 0.1146 - val_loss: 0.8046 - val_accuracy: 0.8320 - val_mse: 0.1393 - val_mae: 0.2062\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.1841 - accuracy: 0.9205 - mse: 0.0566 - mae: 0.1127 - val_loss: 0.7760 - val_accuracy: 0.8395 - val_mse: 0.1321 - val_mae: 0.1883\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 724us/step - loss: 0.1712 - accuracy: 0.9247 - mse: 0.0535 - mae: 0.1079 - val_loss: 0.8352 - val_accuracy: 0.8325 - val_mse: 0.1379 - val_mae: 0.2006\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 724us/step - loss: 0.1755 - accuracy: 0.9221 - mse: 0.0548 - mae: 0.1094 - val_loss: 0.8378 - val_accuracy: 0.8300 - val_mse: 0.1408 - val_mae: 0.1977\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 698us/step - loss: 0.1814 - accuracy: 0.9227 - mse: 0.0563 - mae: 0.1102 - val_loss: 0.7982 - val_accuracy: 0.8310 - val_mse: 0.1389 - val_mae: 0.1974\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.1854 - accuracy: 0.9220 - mse: 0.0570 - mae: 0.1141 - val_loss: 0.8520 - val_accuracy: 0.8345 - val_mse: 0.1355 - val_mae: 0.1878\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.1798 - accuracy: 0.9218 - mse: 0.0559 - mae: 0.1108 - val_loss: 0.8039 - val_accuracy: 0.8360 - val_mse: 0.1367 - val_mae: 0.2025\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.1759 - accuracy: 0.9241 - mse: 0.0547 - mae: 0.1097 - val_loss: 0.8585 - val_accuracy: 0.8375 - val_mse: 0.1353 - val_mae: 0.1881\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 667us/step - loss: 0.1793 - accuracy: 0.9250 - mse: 0.0553 - mae: 0.1088 - val_loss: 0.8430 - val_accuracy: 0.8370 - val_mse: 0.1375 - val_mae: 0.1946\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 664us/step - loss: 0.1846 - accuracy: 0.9215 - mse: 0.0564 - mae: 0.1110 - val_loss: 0.8182 - val_accuracy: 0.8330 - val_mse: 0.1384 - val_mae: 0.1973\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.1806 - accuracy: 0.9212 - mse: 0.0563 - mae: 0.1110 - val_loss: 0.7821 - val_accuracy: 0.8305 - val_mse: 0.1388 - val_mae: 0.2020\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.1772 - accuracy: 0.9230 - mse: 0.0550 - mae: 0.1096 - val_loss: 0.8456 - val_accuracy: 0.8330 - val_mse: 0.1396 - val_mae: 0.1968\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.1767 - accuracy: 0.9231 - mse: 0.0551 - mae: 0.1089 - val_loss: 0.8429 - val_accuracy: 0.8320 - val_mse: 0.1381 - val_mae: 0.2019\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 663us/step - loss: 0.1820 - accuracy: 0.9231 - mse: 0.0561 - mae: 0.1115 - val_loss: 0.8735 - val_accuracy: 0.8310 - val_mse: 0.1405 - val_mae: 0.1992\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 663us/step - loss: 0.1662 - accuracy: 0.9275 - mse: 0.0518 - mae: 0.1041 - val_loss: 0.8854 - val_accuracy: 0.8295 - val_mse: 0.1386 - val_mae: 0.1921\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.1672 - accuracy: 0.9273 - mse: 0.0520 - mae: 0.1038 - val_loss: 0.9781 - val_accuracy: 0.8375 - val_mse: 0.1356 - val_mae: 0.1906\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 665us/step - loss: 0.1730 - accuracy: 0.9261 - mse: 0.0535 - mae: 0.1069 - val_loss: 0.9273 - val_accuracy: 0.8320 - val_mse: 0.1395 - val_mae: 0.1939\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 819us/step - loss: 0.1797 - accuracy: 0.9219 - mse: 0.0555 - mae: 0.1089 - val_loss: 0.8957 - val_accuracy: 0.8320 - val_mse: 0.1386 - val_mae: 0.1944\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 694us/step - loss: 0.1824 - accuracy: 0.9210 - mse: 0.0563 - mae: 0.1111 - val_loss: 0.8395 - val_accuracy: 0.8330 - val_mse: 0.1405 - val_mae: 0.1948\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 689us/step - loss: 0.1753 - accuracy: 0.9239 - mse: 0.0542 - mae: 0.1082 - val_loss: 0.8891 - val_accuracy: 0.8295 - val_mse: 0.1390 - val_mae: 0.1935\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 671us/step - loss: 0.1730 - accuracy: 0.9259 - mse: 0.0539 - mae: 0.1073 - val_loss: 0.8907 - val_accuracy: 0.8250 - val_mse: 0.1443 - val_mae: 0.2063\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 661us/step - loss: 0.1725 - accuracy: 0.9237 - mse: 0.0541 - mae: 0.1063 - val_loss: 0.8581 - val_accuracy: 0.8375 - val_mse: 0.1354 - val_mae: 0.1900\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.1741 - accuracy: 0.9245 - mse: 0.0542 - mae: 0.1074 - val_loss: 0.8792 - val_accuracy: 0.8305 - val_mse: 0.1389 - val_mae: 0.1953\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 667us/step - loss: 0.1708 - accuracy: 0.9233 - mse: 0.0533 - mae: 0.1054 - val_loss: 0.9910 - val_accuracy: 0.8335 - val_mse: 0.1420 - val_mae: 0.2010\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 818us/step - loss: 0.1730 - accuracy: 0.9258 - mse: 0.0535 - mae: 0.1075 - val_loss: 0.9701 - val_accuracy: 0.8250 - val_mse: 0.1464 - val_mae: 0.2031\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.1694 - accuracy: 0.9273 - mse: 0.0518 - mae: 0.1041 - val_loss: 1.0066 - val_accuracy: 0.8310 - val_mse: 0.1412 - val_mae: 0.1935\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.1856 - accuracy: 0.9172 - mse: 0.0579 - mae: 0.1122 - val_loss: 0.9295 - val_accuracy: 0.8295 - val_mse: 0.1431 - val_mae: 0.2040\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.1824 - accuracy: 0.9206 - mse: 0.0562 - mae: 0.1118 - val_loss: 0.9740 - val_accuracy: 0.8245 - val_mse: 0.1462 - val_mae: 0.2013\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 666us/step - loss: 0.1766 - accuracy: 0.9227 - mse: 0.0550 - mae: 0.1074 - val_loss: 0.9108 - val_accuracy: 0.8240 - val_mse: 0.1447 - val_mae: 0.2010\n"
     ]
    }
   ],
   "source": [
    "### Train the model\n",
    "\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test), epochs=100, callbacks=[tf_callback, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parthabhang/Desktop/DL/Churn Bank Project/churnenv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load tensorflow extension\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 65371), started 0:04:22 ago. (Use '!kill 65371' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c7211be30f0c4491\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c7211be30f0c4491\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit20241207-214525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
