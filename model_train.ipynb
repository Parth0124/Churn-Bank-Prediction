{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_test_split.pkl', 'rb') as f:\n",
    "    x_train, x_test, y_train, y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.shape[1],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),  ##Hidden Layer 1\n",
    "    Dense(32, activation='relu'),  ##Hidden Layer 2\n",
    "    Dense(1, activation='sigmoid')  ##Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                832       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "optimizser = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compiling the model\n",
    "\n",
    "model.compile(optimizer=optimizser, loss='binary_crossentropy', metrics=['accuracy', 'mse', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above are the 2 ways to give values to a model.You can either pass it in the form of an array or you can directly initialize it to a variable and pass the vaariable as an argument to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the tensorboard\n",
    "\n",
    "log_dir = 'logs/fit/'+datetime.datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up earlystopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.3922 - accuracy: 0.8388 - mse: 0.1209 - mae: 0.2432 - val_loss: 0.3570 - val_accuracy: 0.8525 - val_mse: 0.1091 - val_mae: 0.2067\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.3518 - accuracy: 0.8593 - mse: 0.1070 - mae: 0.2138 - val_loss: 0.3646 - val_accuracy: 0.8500 - val_mse: 0.1108 - val_mae: 0.2058\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 657us/step - loss: 0.3476 - accuracy: 0.8597 - mse: 0.1052 - mae: 0.2096 - val_loss: 0.3551 - val_accuracy: 0.8525 - val_mse: 0.1093 - val_mae: 0.2315\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 660us/step - loss: 0.3419 - accuracy: 0.8575 - mse: 0.1039 - mae: 0.2082 - val_loss: 0.3479 - val_accuracy: 0.8550 - val_mse: 0.1067 - val_mae: 0.2198\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 656us/step - loss: 0.3386 - accuracy: 0.8636 - mse: 0.1024 - mae: 0.2037 - val_loss: 0.3564 - val_accuracy: 0.8460 - val_mse: 0.1093 - val_mae: 0.2071\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 660us/step - loss: 0.3376 - accuracy: 0.8602 - mse: 0.1025 - mae: 0.2056 - val_loss: 0.3557 - val_accuracy: 0.8580 - val_mse: 0.1080 - val_mae: 0.1978\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 657us/step - loss: 0.3337 - accuracy: 0.8627 - mse: 0.1017 - mae: 0.2025 - val_loss: 0.3482 - val_accuracy: 0.8540 - val_mse: 0.1061 - val_mae: 0.2162\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 711us/step - loss: 0.3312 - accuracy: 0.8646 - mse: 0.1004 - mae: 0.2002 - val_loss: 0.3579 - val_accuracy: 0.8545 - val_mse: 0.1100 - val_mae: 0.2192\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.3310 - accuracy: 0.8639 - mse: 0.1006 - mae: 0.2002 - val_loss: 0.3460 - val_accuracy: 0.8570 - val_mse: 0.1044 - val_mae: 0.2185\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 662us/step - loss: 0.3269 - accuracy: 0.8671 - mse: 0.0989 - mae: 0.1980 - val_loss: 0.3628 - val_accuracy: 0.8575 - val_mse: 0.1079 - val_mae: 0.1880\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 707us/step - loss: 0.3255 - accuracy: 0.8662 - mse: 0.0985 - mae: 0.1948 - val_loss: 0.3527 - val_accuracy: 0.8540 - val_mse: 0.1081 - val_mae: 0.2049\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 815us/step - loss: 0.3242 - accuracy: 0.8674 - mse: 0.0983 - mae: 0.1959 - val_loss: 0.3644 - val_accuracy: 0.8595 - val_mse: 0.1096 - val_mae: 0.2398\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8724 - mse: 0.0969 - mae: 0.1935 - val_loss: 0.3566 - val_accuracy: 0.8560 - val_mse: 0.1075 - val_mae: 0.2209\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 727us/step - loss: 0.3212 - accuracy: 0.8708 - mse: 0.0972 - mae: 0.1941 - val_loss: 0.3669 - val_accuracy: 0.8540 - val_mse: 0.1097 - val_mae: 0.1910\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 688us/step - loss: 0.3193 - accuracy: 0.8705 - mse: 0.0964 - mae: 0.1919 - val_loss: 0.3513 - val_accuracy: 0.8565 - val_mse: 0.1070 - val_mae: 0.2208\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 683us/step - loss: 0.3147 - accuracy: 0.8708 - mse: 0.0955 - mae: 0.1906 - val_loss: 0.3590 - val_accuracy: 0.8590 - val_mse: 0.1067 - val_mae: 0.1962\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 718us/step - loss: 0.3131 - accuracy: 0.8706 - mse: 0.0950 - mae: 0.1885 - val_loss: 0.3647 - val_accuracy: 0.8515 - val_mse: 0.1092 - val_mae: 0.1968\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 739us/step - loss: 0.3098 - accuracy: 0.8754 - mse: 0.0938 - mae: 0.1880 - val_loss: 0.3677 - val_accuracy: 0.8610 - val_mse: 0.1076 - val_mae: 0.2049\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 717us/step - loss: 0.3104 - accuracy: 0.8764 - mse: 0.0937 - mae: 0.1858 - val_loss: 0.3688 - val_accuracy: 0.8550 - val_mse: 0.1092 - val_mae: 0.2124\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 726us/step - loss: 0.3056 - accuracy: 0.8786 - mse: 0.0921 - mae: 0.1839 - val_loss: 0.3838 - val_accuracy: 0.8570 - val_mse: 0.1104 - val_mae: 0.2108\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 691us/step - loss: 0.3041 - accuracy: 0.8750 - mse: 0.0923 - mae: 0.1859 - val_loss: 0.3870 - val_accuracy: 0.8580 - val_mse: 0.1105 - val_mae: 0.1915\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 734us/step - loss: 0.3043 - accuracy: 0.8767 - mse: 0.0921 - mae: 0.1829 - val_loss: 0.3758 - val_accuracy: 0.8600 - val_mse: 0.1079 - val_mae: 0.1917\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 685us/step - loss: 0.2997 - accuracy: 0.8798 - mse: 0.0904 - mae: 0.1817 - val_loss: 0.4065 - val_accuracy: 0.8495 - val_mse: 0.1135 - val_mae: 0.1851\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 672us/step - loss: 0.2965 - accuracy: 0.8801 - mse: 0.0893 - mae: 0.1757 - val_loss: 0.3874 - val_accuracy: 0.8570 - val_mse: 0.1115 - val_mae: 0.2001\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 679us/step - loss: 0.2940 - accuracy: 0.8808 - mse: 0.0886 - mae: 0.1767 - val_loss: 0.3820 - val_accuracy: 0.8540 - val_mse: 0.1122 - val_mae: 0.2095\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.2948 - accuracy: 0.8791 - mse: 0.0895 - mae: 0.1779 - val_loss: 0.3951 - val_accuracy: 0.8530 - val_mse: 0.1133 - val_mae: 0.1988\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 671us/step - loss: 0.2866 - accuracy: 0.8836 - mse: 0.0866 - mae: 0.1721 - val_loss: 0.3998 - val_accuracy: 0.8505 - val_mse: 0.1153 - val_mae: 0.2075\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 670us/step - loss: 0.2885 - accuracy: 0.8844 - mse: 0.0872 - mae: 0.1727 - val_loss: 0.3986 - val_accuracy: 0.8475 - val_mse: 0.1138 - val_mae: 0.1953\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 669us/step - loss: 0.2822 - accuracy: 0.8827 - mse: 0.0859 - mae: 0.1714 - val_loss: 0.3989 - val_accuracy: 0.8565 - val_mse: 0.1128 - val_mae: 0.1895\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 674us/step - loss: 0.2841 - accuracy: 0.8870 - mse: 0.0858 - mae: 0.1708 - val_loss: 0.4327 - val_accuracy: 0.8515 - val_mse: 0.1175 - val_mae: 0.1894\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 671us/step - loss: 0.2828 - accuracy: 0.8840 - mse: 0.0859 - mae: 0.1710 - val_loss: 0.3920 - val_accuracy: 0.8490 - val_mse: 0.1131 - val_mae: 0.2013\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 704us/step - loss: 0.2792 - accuracy: 0.8884 - mse: 0.0842 - mae: 0.1665 - val_loss: 0.4061 - val_accuracy: 0.8510 - val_mse: 0.1136 - val_mae: 0.2011\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 722us/step - loss: 0.2763 - accuracy: 0.8903 - mse: 0.0831 - mae: 0.1661 - val_loss: 0.4479 - val_accuracy: 0.8530 - val_mse: 0.1181 - val_mae: 0.1830\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 721us/step - loss: 0.2757 - accuracy: 0.8895 - mse: 0.0829 - mae: 0.1649 - val_loss: 0.4328 - val_accuracy: 0.8500 - val_mse: 0.1139 - val_mae: 0.1918\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 671us/step - loss: 0.2764 - accuracy: 0.8903 - mse: 0.0839 - mae: 0.1665 - val_loss: 0.4254 - val_accuracy: 0.8595 - val_mse: 0.1126 - val_mae: 0.1925\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 668us/step - loss: 0.2690 - accuracy: 0.8896 - mse: 0.0811 - mae: 0.1614 - val_loss: 0.4628 - val_accuracy: 0.8575 - val_mse: 0.1152 - val_mae: 0.1951\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 673us/step - loss: 0.2682 - accuracy: 0.8909 - mse: 0.0813 - mae: 0.1608 - val_loss: 0.3925 - val_accuracy: 0.8565 - val_mse: 0.1113 - val_mae: 0.2007\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 680us/step - loss: 0.2688 - accuracy: 0.8939 - mse: 0.0808 - mae: 0.1612 - val_loss: 0.4408 - val_accuracy: 0.8560 - val_mse: 0.1137 - val_mae: 0.1959\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 681us/step - loss: 0.2649 - accuracy: 0.8926 - mse: 0.0799 - mae: 0.1594 - val_loss: 0.4664 - val_accuracy: 0.8525 - val_mse: 0.1184 - val_mae: 0.1907\n"
     ]
    }
   ],
   "source": [
    "### Train the model\n",
    "\n",
    "history = model.fit(x_train,y_train,validation_data=(x_test,y_test), epochs=100, callbacks=[tf_callback, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parthabhang/Desktop/DL/Churn Bank Project/churnenv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load tensorflow extension\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 69900), started 0:00:34 ago. (Use '!kill 69900' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6950eacab7b3b854\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6950eacab7b3b854\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit20241207-214525"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
